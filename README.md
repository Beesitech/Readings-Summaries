# Resources
### Insightlful papers

+ How Does Batch Normalization Help Optimization?: https://arxiv.org/pdf/1805.11604.pdf

+ Generative models for discovering sparse distributedrepresentations (Hinton 1997) https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.1997.0101

### Math ideas

+ Gradient, Divergence, Curland Related Formulae: http://bolvan.ph.utexas.edu/~vadim/Classes/2018f/diffop.pdf

+ Taylor expansion theory : http://pathfinder.scar.utoronto.ca/~dyer/csca57/book_P/node26.html

+ ICA https://arxiv.org/pdf/1404.2986.pdf

+ PCA https://arxiv.org/pdf/1404.1100.pdf

+ CCA https://www.cs.cmu.edu/~tom/10701_sp11/slides/CCA_tutorial.pdf

+ Statstics Resouces https://www.ics.uci.edu/~smyth/courses/cs274/notes.html

+ RKHS http://mlss.tuebingen.mpg.de/2015/slides/gretton/part_1.pdf

+ Optimal Transport and Wasserstein Distance http://www.stat.cmu.edu/~larry/=sml/Opt.pdf

+ Integral probablity metrics https://arxiv.org/pdf/0901.2698.pdf, https://sci-hub.tw/10.2307/1428011

### Information Theory

+ MIT Lecture notes http://people.lids.mit.edu/yp/homepage/data/itlectures_v5.pdf

+ The information bottleneck method https://arxiv.org/pdf/physics/0004057.pdf

+ Deep  Learning  and  the  Information  Bottleneck  Principle https://arxiv.org/pdf/1503.02406.pdf

+ Mutual Information Neural Estimation https://arxiv.org/pdf/1801.04062.pdf

+ Compression https://www.cs.cmu.edu/~guyb/realworld/compression.pdf

+ KL vs Reverse-KL https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/

### Optimization

+ Steepest descent and Natural Gradients https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gradientDescent.pdf
+ Topologies and neural networks https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/

### Machine Learning

+ SVM http://cs229.stanford.edu/notes/cs229-notes3.pdf

+ Stein Methods https://www.cs.dartmouth.edu/~qliu/PDF/steinslides16.pdf

+ Gaussian Processes https://distill.pub/2019/visual-exploration-gaussian-processes/, http://www.gaussianprocess.org/gpml/chapters/RW2.pdf, Code: https://github.com/cornellius-gp/gpytorch/blob/master/examples/01_Simple_GP_Regression/Simple_GP_Regression.ipynb

+ Neural Processes https://kasparmartens.rbind.io/post/np/ , starter codes https://github.com/deepmind/neural-processes

+ List of Michael Jordan Tutorials https://people.eecs.berkeley.edu/~jordan/tutorials.html

+ MMD http://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf

### Computer Vision

+ Optical Flow: https://blog.nanonets.com/optical-flow/, https://reader.elsevier.com/reader/sd/pii/S0923596518302479?token=8E5DDBE77C9294FB10D4B64081DA1F40947D46C1331F6AEE20C052A2587D5ABC770E3663B8632E7122D2EF1CF4595401


### Practical

+ Mixed precision (Apex) https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9998-automatic-mixed-precision-in-pytorch.pdf
